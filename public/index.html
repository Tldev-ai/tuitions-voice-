<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>iiTuitions — Voice</title>
  <style>
    /* === black/white text + light blue background gradient === */
    :root{
      --ink:#000000;     /* all text in black */
      --ring:#e5e7eb;
      --idle:#bbbbbb;    /* mic LED idle (grey) */
    }
    *{box-sizing:border-box}
    body{
      margin:0;
      color:var(--ink);
      font:16px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Inter,sans-serif;
      background: linear-gradient(180deg, #9EC3F2 0%, #DCE7F7 100%);
      min-height:100vh;
    }

    .top{
      display:flex;align-items:center;gap:10px;
      border-bottom:1px solid var(--ring);
      padding:12px 16px;
      background:#ffffffcc; /* white with slight transparency */
      backdrop-filter:saturate(120%) blur(6px);
    }
    .brand{display:flex;align-items:center;gap:8px;text-decoration:none;color:var(--ink);font-weight:800}

    .wrap{max-width:980px;margin:28px auto;padding:0 16px}
    .card{padding:24px;border:1px solid var(--ring);border-radius:16px;box-shadow:0 6px 28px rgba(0,0,0,.06);background:#fff}

    h1{margin:0 0 10px;color:#000}
    p{margin:0 0 14px;color:#000}
    .sub{margin:-6px 0 14px;font-weight:600}
    .muted{opacity:.9}

    .consent{display:flex;align-items:center;gap:8px;color:#000;margin-top:10px}

    .row{display:flex;gap:12px;align-items:center;margin-top:12px;flex-wrap:wrap}

    /* Buttons: black/white only. Make Start Voice wider horizontally */
    button{
      display:inline-flex;gap:8px;align-items:center;justify-content:center;
      padding:12px 16px;border-radius:999px;border:0;background:#000;color:#fff;
      font-weight:800;cursor:pointer;letter-spacing:.2px
    }
    #startBtn{
      min-width: 320px;        /* wider */
      padding: 14px 36px;      /* more horizontal padding */
      font-size: 18px;         /* a bit larger text */
    }
    button.end{background:#000;color:#fff;border:2px solid #000} /* keep B/W theme */
    button:disabled{opacity:.6;cursor:not-allowed}

    .fine{font-size:12px;color:#000;margin-top:8px}

    audio{display:none}

    /* LED: keep black/white (idle grey, active black) */
    .led{width:10px;height:10px;border-radius:999px;background:var(--idle);box-shadow:0 0 0 1px #00000010}
    .led.on{background:#000}

    /* content lists */
    ul, ol{margin:8px 0 14px 20px}
    li{margin:4px 0}
    .section-title{font-weight:800;margin-top:10px}
    .divider{height:1px;background:#eee;margin:14px 0;border-radius:1px}
    .footer-note{font-size:13px;margin-top:2px}
    .right{float:right}
    @media (max-width:640px){ .right{float:none;display:block;margin-top:6px} }
  </style>
</head>
<body>
  <header class="top">
    <!-- Ensure this exists at /public/assets/iituitions-logo.png -->
    <a class="brand" href="#"><img src="/assets/iituitions-logo.png" alt="logo" style="height:24px"> iiTuitions</a>
  </header>

  <main class="wrap">
    <section class="card">
      <h1>Talk to our Admissions Assistant</h1>
      <p class="sub muted">Get answers in <b>2–3 minutes</b>. Available in <b>English / తెలుగు / हिन्दी</b>.</p>

      <p>Click below to speak. Your conversation is recorded (audio + summary) for follow-up.</p>

      <div class="section-title">I can help with</div>
      <ul>
        <li>Course options, fees, and current batches</li>
        <li>Home tutoring vs. online classes</li>
        <li>Board/grade &amp; subject guidance</li>
        <li>Demo class and timings</li>
        <li>Scholarships / discounts (if available)</li>
      </ul>

      <div class="section-title">Keep these handy</div>
      <ul>
        <li>Student name &amp; grade/board</li>
        <li>Subjects needed</li>
        <li>Location or <b>Online</b> preference</li>
        <li>Preferred time to call back</li>
        <li>Budget range (optional)</li>
      </ul>

      <label class="consent">
        <input type="checkbox" id="consent" />
        I agree to the recording and storage of this conversation.
      </label>

      <div class="row">
        <button id="startBtn">Start Voice</button>
        <button id="endBtn" class="end" disabled>End</button>
        <span class="led" id="led" title="Mic activity"></span>
        <audio id="aiAudio" autoplay playsinline></audio>
      </div>

      <div class="fine">Tip: say <b>“Switch to Telugu”</b> or <b>“Switch to Hindi”</b> anytime.</div>

      <div class="divider"></div>

      <div class="section-title">What happens after this call</div>
      <ol>
        <li>You’ll get a short <b>summary</b> of the call.</li>
        <li>Our counselor will reach out within <b>one working day</b>.</li>
        <li>If you want a demo, we’ll schedule it for your preferred time.</li>
      </ol>

      <p class="footer-note"><b>Privacy:</b> We record this call (audio + summary) only for admission support and store it securely in our institute’s Google Drive. We never share your data outside iiTuitions.
        <span class="right">Prefer a person? Call <b>+91-XXXXXXXXXX</b></span>
      </p>

      <!-- hidden log (optional while debugging) -->
      <pre id="log" style="display:none"></pre>
    </section>
  </main>

  <!-- ===== Voice logic with reliable Realtime flow ===== -->
  <script>
    const startBtn = document.getElementById('startBtn');
    const endBtn   = document.getElementById('endBtn');
    const aiAudio  = document.getElementById('aiAudio');
    const consent  = document.getElementById('consent');
    const led      = document.getElementById('led');
    const logEl    = document.getElementById('log');

    function log(...args){ console.log('[voice]', ...args); if(logEl){ logEl.textContent += args.map(a => (typeof a==='string'?a:JSON.stringify(a))).join(' ') + '\n'; } }

    let pc, dc, localStream, remoteStream, mediaRecorder, recordedChunks = [];
    let silenceRAF, silenceTimer, analyser, dataArray;

    const SILENCE_MS = 15000;
    const RMS_THRESHOLD = 0.006;

    function timeOfDay(){ const h=new Date().getHours(); return h<12?'morning':h<17?'afternoon':h<21?'evening':'night'; }

    async function fetchEphemeral(){
      const res = await fetch('/api/session', { headers:{ 'cache-control':'no-store' } });
      if(!res.ok){
        let msg = '';
        try { msg = (await res.json()).error || ''; } catch(e){}
        throw new Error(`Ephemeral fetch failed (${res.status}) ${msg}`);
      }
      return res.json();
    }

    async function postSDP(ephemeral, model, sdp){
      const url = `https://api.openai.com/v1/realtime?model=${encodeURIComponent(model || 'gpt-4o-realtime-preview')}`;
      const r = await fetch(url, {
        method: 'POST',
        headers: { 'Authorization': `Bearer ${ephemeral}`, 'Content-Type': 'application/sdp' },
        body: sdp
      });
      return r;
    }

    async function startCall() {
      try {
        if (!consent.checked) { alert('Please provide consent to proceed.'); return; }
        startBtn.disabled = true; endBtn.disabled = false; logEl.style.display='block';

        // 1) Get ephemeral quickly (keep total time < ~60s)
        log('Fetching ephemeral…');
        const sess = await fetchEphemeral();
        const EPHEMERAL = sess.client_secret?.value;
        const MODEL = sess.model || 'gpt-4o-realtime-preview';
        if(!EPHEMERAL){ throw new Error('No client_secret in /api/session response'); }
        log('Ephemeral ok, model =', MODEL);

        // 2) RTCPeerConnection with STUN servers (improves connectivity)
        pc = new RTCPeerConnection({
          iceServers: [
            { urls: 'stun:stun.l.google.com:19302' },
            { urls: 'stun:global.stun.twilio.com:3478?transport=udp' }
          ]
        });

        pc.onconnectionstatechange = () => log('PC state:', pc.connectionState);
        pc.onicegatheringstatechange = () => log('ICE gather:', pc.iceGatheringState);
        pc.onicecandidateerror = e => log('ICE candidate error:', e.errorText || e);

        // Data channel for initial greeting
        dc = pc.createDataChannel('oai-events');
        dc.onopen = () => {
          log('DataChannel open → send greeting');
          const greet = `Hai. Good ${timeOfDay()}. Which language would you like to talk in — English, తెలుగు (Telugu), or हिन्दी (Hindi)?`;
          try { dc.send(JSON.stringify({ type:'response.create', response:{ instructions:greet } })); } catch (e) { log('DC send error', e); }
        };

        // 3) Microphone
        try {
          localStream = await navigator.mediaDevices.getUserMedia({
            audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true }
          });
        } catch (e) {
          alert('Microphone blocked. Click the mic icon in the address bar and Allow, then reload.');
          throw e;
        }
        localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

        // 4) Remote audio hookup + recorder + VAD
        pc.ontrack = (ev) => {
          log('Got remote track');
          remoteStream = ev.streams[0];
          aiAudio.srcObject = remoteStream;
          aiAudio.muted = false;
          aiAudio.autoplay = true;
          aiAudio.play().catch(err => log('audio.play error:', err));

          const ctx = new (window.AudioContext || window.webkitAudioContext)();
          const dest = ctx.createMediaStreamDestination();

          const micSrc = ctx.createMediaStreamSource(localStream);
          const aiSrc  = ctx.createMediaStreamSource(remoteStream);
          micSrc.connect(dest); aiSrc.connect(dest);

          analyser = ctx.createAnalyser(); analyser.fftSize = 2048;
          const micTap = ctx.createMediaStreamSource(localStream);
          micTap.connect(analyser);
          dataArray = new Float32Array(analyser.fftSize);

          const resetSilence = () => {
            if (silenceTimer) clearTimeout(silenceTimer);
            silenceTimer = setTimeout(() => {
              try {
                dc?.send(JSON.stringify({ type:'response.create', response:{ instructions:"Sorry, I'm unable to hear you. I'll end this call now." } }));
              } catch {}
              setTimeout(endCall, 1800);
            }, SILENCE_MS);
          };

          const monitor = () => {
            analyser.getFloatTimeDomainData(dataArray);
            let rms = 0; for (let i=0;i<dataArray.length;i++){ const v=dataArray[i]; rms += v*v; }
            rms = Math.sqrt(rms / dataArray.length);
            if (rms > RMS_THRESHOLD) { led.classList.add('on'); resetSilence(); } else { led.classList.remove('on'); }
            silenceRAF = requestAnimationFrame(monitor);
          };
          setTimeout(()=>{ resetSilence(); monitor(); }, 1200);

          try { mediaRecorder = new MediaRecorder(dest.stream, { mimeType: 'audio/webm;codecs=opus' }); }
          catch { mediaRecorder = new MediaRecorder(dest.stream); }
          mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) recordedChunks.push(e.data); };
          mediaRecorder.start(250);
        };

        // 5) Offer → wait for full ICE gather (or 2s max)
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        await new Promise((resolve) => {
          if (pc.iceGatheringState === 'complete') return resolve();
          const to = setTimeout(resolve, 2000);
          pc.onicegatheringstatechange = () => {
            if (pc.iceGatheringState === 'complete') { clearTimeout(to); resolve(); }
          };
        });

        // 6) POST SDP (retry once on 401/403)
        log('Posting SDP…');
        let r = await postSDP(EPHEMERAL, MODEL, pc.localDescription.sdp);
        if (r.status === 401 || r.status === 403) {
          log('SDP unauthorized, refreshing ephemeral once…');
          const again = await fetchEphemeral();
          const EPH2 = again.client_secret?.value;
          if(!EPH2) throw new Error('Second ephemeral fetch returned no client_secret');
          r = await postSDP(EPH2, MODEL, pc.localDescription.sdp);
        }
        if (!r.ok) {
          const text = await r.text();
          log('SDP post failed:', r.status, text);
          alert(`Failed to start audio session.\nStatus: ${r.status}\n${text}`);
          throw new Error(`SDP post failed ${r.status}`);
        }

        const answer = { type: 'answer', sdp: await r.text() };
        await pc.setRemoteDescription(answer);
        log('Remote description set — waiting for connection…');

      } catch (err) {
        log('startCall error:', err?.message || err);
        try { await endCall(); } catch {}
        startBtn.disabled = false; endBtn.disabled = true;
      }
    }

    async function endCall() {
      endBtn.disabled = true;
      try { if (silenceTimer) clearTimeout(silenceTimer); if (silenceRAF) cancelAnimationFrame(silenceRAF); } catch {}
      try { mediaRecorder && mediaRecorder.stop(); } catch {}
      try { pc && pc.close(); } catch {}
      try { localStream && localStream.getTracks().forEach(t => t.stop()); } catch {}

      try {
        if (recordedChunks.length) {
          const audioBlob = new Blob(recordedChunks, { type: 'audio/webm' });
          const form = new FormData();
          form.append('audio', audioBlob, 'conversation.webm');
          form.append('transcriptJson', JSON.stringify({ endedAt: new Date().toISOString() }));
          const up = await fetch('/api/upload', { method: 'POST', body: form });
          log('Upload status:', up.status);
        }
      } catch (e){ log('Upload error:', e); }

      recordedChunks = [];
      startBtn.disabled = false;
    }

    startBtn.addEventListener('click', startCall);
    endBtn.addEventListener('click', endCall);
  </script>
</body>
</html>
