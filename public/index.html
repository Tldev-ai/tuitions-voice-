<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>iiTuitions — Voice</title>
  <style>
    :root{ --ink:#000; --ring:#e5e7eb; --idle:#bbb; }
    *{box-sizing:border-box}
    body{ margin:0; color:var(--ink); font:16px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Inter,sans-serif;
          background:linear-gradient(180deg,#9EC3F2 0%,#DCE7F7 100%); min-height:100vh; }
    .top{ display:flex; align-items:center; gap:10px; border-bottom:1px solid var(--ring);
          padding:12px 16px; background:#ffffffcc; backdrop-filter:saturate(120%) blur(6px); }
    .brand{ display:flex; align-items:center; gap:8px; text-decoration:none; color:var(--ink); font-weight:800 }
    .wrap{ max-width:980px; margin:28px auto; padding:0 16px }
    .card{ padding:24px; border:1px solid var(--ring); border-radius:16px; box-shadow:0 6px 28px rgba(0,0,0,.06); background:#fff }
    h1{ margin:0 0 10px } p{ margin:0 0 14px }
    .sub{ margin:-6px 0 14px; font-weight:600 } .muted{ opacity:.9 }
    .consent{ display:flex; align-items:center; gap:8px; margin-top:10px }
    .row{ display:flex; gap:12px; align-items:center; margin-top:12px; flex-wrap:wrap }
    button{ display:inline-flex; gap:8px; align-items:center; justify-content:center; padding:12px 16px;
            border-radius:999px; border:0; background:#000; color:#fff; font-weight:800; cursor:pointer; letter-spacing:.2px }
    #startBtn{ min-width:320px; padding:14px 36px; font-size:18px }
    button.end{ background:#000; color:#fff; border:2px solid #000 }
    button:disabled{ opacity:.6; cursor:not-allowed }
    .fine{ font-size:12px; margin-top:8px }
    audio{ display:none }
    .led{ width:10px; height:10px; border-radius:999px; background:var(--idle); box-shadow:0 0 0 1px #00000010 }
    .led.on{ background:#000 }
    ul,ol{ margin:8px 0 14px 20px } li{ margin:4px 0 }
    .section-title{ font-weight:800; margin-top:10px }
    .divider{ height:1px; background:#eee; margin:14px 0; border-radius:1px }
    .footer-note{ font-size:13px; margin-top:2px }
    .right{ float:right } @media (max-width:640px){ .right{ float:none; display:block; margin-top:6px } }
  </style>
</head>
<body>
  <header class="top">
    <!-- Ensure this exists at /public/assets/iituitions-logo.png -->
    <a class="brand" href="#"><img src="/assets/iituitions-logo.png" alt="logo" style="height:24px"> iiTuitions</a>
  </header>

  <main class="wrap">
    <section class="card">
      <h1>Talk to our Admissions Assistant</h1>
      <p class="sub muted">Get answers in <b>2–3 minutes</b>. Available in <b>English / తెలుగు / हिन्दी</b>.</p>
      <p>Click below to speak. Your conversation is recorded (audio + summary) for follow-up.</p>

      <div class="section-title">I can help with</div>
      <ul>
        <li>Course options, fees, and current batches</li>
        <li>Home tutoring vs. online classes</li>
        <li>Board/grade &amp; subject guidance</li>
        <li>Demo class and timings</li>
        <li>Scholarships / discounts (if available)</li>
      </ul>

      <div class="section-title">Keep these handy</div>
      <ul>
        <li>Student name &amp; grade/board</li>
        <li>Subjects needed</li>
        <li>Location or <b>Online</b> preference</li>
        <li>Preferred time to call back</li>
        <li>Budget range (optional)</li>
      </ul>

      <label class="consent">
        <input type="checkbox" id="consent" />
        I agree to the recording and storage of this conversation.
      </label>

      <div class="row">
        <button id="startBtn">Start Voice</button>
        <button id="endBtn" class="end" disabled>End</button>
        <span class="led" id="led" title="Mic activity"></span>
        <audio id="aiAudio" autoplay playsinline></audio>
      </div>

      <div class="fine">Tip: say <b>“Switch to Telugu”</b> or <b>“Switch to Hindi”</b> anytime.</div>
      <div class="divider"></div>

      <div class="section-title">What happens after this call</div>
      <ol>
        <li>You’ll get a short <b>summary</b> of the call.</li>
        <li>Our counselor will reach out within <b>one working day</b>.</li>
        <li>If you want a demo, we’ll schedule it for your preferred time.</li>
      </ol>

      <p class="footer-note"><b>Privacy:</b> We record this call (audio + summary) only for admission support and store it securely in our institute’s Google Drive. We never share your data outside iiTuitions.
        <span class="right">Prefer a person? Call <b>+91-XXXXXXXXXX</b></span>
      </p>

      <pre id="log" style="display:none"></pre>
    </section>
  </main>

  <script>
    const startBtn = document.getElementById('startBtn');
    const endBtn   = document.getElementById('endBtn');
    const aiAudio  = document.getElementById('aiAudio');
    const consent  = document.getElementById('consent');
    const led      = document.getElementById('led');
    const logEl    = document.getElementById('log');
    function log(...a){ console.log('[voice]', ...a); if(logEl){ logEl.style.display='block'; logEl.textContent += a.map(x=>typeof x==='string'?x:JSON.stringify(x)).join(' ') + '\n'; } }

    let pc, dc, localStream, remoteStream, mediaRecorder, recordedChunks = [];
    let silenceRAF, silenceTimer, analyser, dataArray;

    const SILENCE_MS = 15000;
    const RMS_THRESHOLD = 0.006;

    function timeOfDay(){ const h=new Date().getHours(); return h<12?'morning':h<17?'afternoon':h<21?'evening':'night'; }

    async function getEphemeral(){
      const r = await fetch('/api/session', { headers:{'cache-control':'no-store'} });
      const text = await r.text();
      if(!r.ok) throw new Error(`Session ${r.status}: ${text}`);
      return JSON.parse(text);
    }

    async function postSDP(ephemeral, model, sdp){
      return fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent(model)}`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${ephemeral}`,
          'Content-Type': 'application/sdp',
          'Accept': 'application/sdp'
        },
        body: sdp
      });
    }

    async function startCall(){
      try{
        if(!consent.checked){ alert('Please provide consent to proceed.'); return; }
        startBtn.disabled = true; endBtn.disabled = false;

        // === ONLY-CHANGED PART: ICE servers + a tiny "no-route" alert timer ===
        pc = new RTCPeerConnection({
          iceServers: [
            // Solid public STUNs
            { urls: ['stun:stun.l.google.com:19302', 'stun:stun1.l.google.com:19302'] },
            { urls: 'stun:stun.cloudflare.com:3478' },
            { urls: 'stun:global.stun.twilio.com:3478' },

            // --- OPTIONAL TURN (uncomment and fill when you have creds) ---
            // {
            //   urls: 'turn:global.turn.twilio.com:3478?transport=udp',
            //   username: '<TWILIO_USERNAME>',
            //   credential: '<TWILIO_CREDENTIAL>'
            // },
            // {
            //   urls: 'turn:global.turn.twilio.com:5349?transport=tcp', // TCP fallback for strict nets
            //   username: '<TWILIO_USERNAME>',
            //   credential: '<TWILIO_CREDENTIAL>'
            // },
          ]
        });

        pc.addTransceiver('audio', { direction: 'recvonly' });

        pc.onconnectionstatechange = () => log('pc state:', pc.connectionState);
        pc.oniceconnectionstatechange = () => log('ice state:', pc.iceConnectionState);
        pc.onicecandidateerror = e => log('ice error:', e.errorText || e);

        // Data channel for greetings + “no-route” hint if it never opens
        dc = pc.createDataChannel('oai-events');
        let dcOpenTimer = setTimeout(()=>{
          if (!dc || dc.readyState !== 'open') {
            alert("Network can't connect to the voice service (ICE). If this keeps happening on this Wi-Fi, enable TURN (uncomment in code and add credentials).");
          }
        }, 8000);
        dc.onopen = () => {
          clearTimeout(dcOpenTimer);
          const greet = `Hai. Good ${timeOfDay()}. Which language would you like to talk in — English, తెలుగు (Telugu), or हिन्दी (Hindi)?`;
          try { dc.send(JSON.stringify({ type:'response.create', response:{ instructions:greet } })); } catch(e){ log('dc send err', e); }
        };

        // Mic
        try{
          localStream = await navigator.mediaDevices.getUserMedia({
            audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true }
          });
        }catch(e){
          alert('Microphone blocked. Click the mic icon in the address bar and Allow, then reload.');
          throw e;
        }
        localStream.getTracks().forEach(t=>pc.addTrack(t, localStream));

        // Remote audio + recorder + simple VAD
        pc.ontrack = (ev)=>{
          log('remote track');
          remoteStream = ev.streams[0];
          aiAudio.srcObject = remoteStream;
          aiAudio.muted = false; aiAudio.autoplay = true;
          aiAudio.play().catch(err=>log('audio.play err:', err));

          const ctx = new (window.AudioContext||window.webkitAudioContext)();
          const dest = ctx.createMediaStreamDestination();
          ctx.resume && ctx.resume().catch(()=>{}); // nudge on iOS/Safari

          const micSrc = ctx.createMediaStreamSource(localStream);
          const aiSrc  = ctx.createMediaStreamSource(remoteStream);
          micSrc.connect(dest); aiSrc.connect(dest);

          analyser = ctx.createAnalyser(); analyser.fftSize = 2048;
          const micTap = ctx.createMediaStreamSource(localStream);
          micTap.connect(analyser);
          dataArray = new Float32Array(analyser.fftSize);

          const resetSilence = ()=>{
            if(silenceTimer) clearTimeout(silenceTimer);
            silenceTimer = setTimeout(()=>{
              try{ dc?.send(JSON.stringify({ type:'response.create', response:{ instructions:"Sorry, I'm unable to hear you. I'll end this call now." } })); }catch{}
              setTimeout(endCall, 1800);
            }, SILENCE_MS);
          };

          const monitor = ()=>{
            analyser.getFloatTimeDomainData(dataArray);
            let rms=0; for(let i=0;i<dataArray.length;i++){ const v=dataArray[i]; rms += v*v; }
            rms = Math.sqrt(rms/dataArray.length);
            if(rms>RMS_THRESHOLD){ led.classList.add('on'); resetSilence(); } else { led.classList.remove('on'); }
            silenceRAF = requestAnimationFrame(monitor);
          };
          setTimeout(()=>{ resetSilence(); monitor(); }, 1200);

          try{ mediaRecorder = new MediaRecorder(dest.stream, { mimeType:'audio/webm;codecs=opus' }); }
          catch{ mediaRecorder = new MediaRecorder(dest.stream); }
          mediaRecorder.ondataavailable = e => { if(e.data.size>0) recordedChunks.push(e.data); };
          mediaRecorder.start(250);
        };

        // Offer + ICE gather (2s max)
        const offer = await pc.createOffer(); await pc.setLocalDescription(offer);
        await new Promise(resolve=>{
          if(pc.iceGatheringState==='complete') return resolve();
          const to=setTimeout(resolve, 2000);
          pc.onicegatheringstatechange=()=>{ if(pc.iceGatheringState==='complete'){ clearTimeout(to); resolve(); } };
        });

        // Ephemeral + SDP post (with one refresh retry)
        const sess = await getEphemeral();
        let token = sess.client_secret?.value;
        const model = sess.model || 'gpt-4o-realtime-preview';
        if(!token) throw new Error('No ephemeral token from /api/session');

        let r = await postSDP(token, model, pc.localDescription.sdp);
        if(r.status===401 || r.status===403){
          log('SDP unauthorized, refreshing ephemeral once…');
          const s2 = await getEphemeral();
          token = s2.client_secret?.value;
          if(!token) throw new Error('Second /api/session returned no token');
          r = await postSDP(token, model, pc.localDescription.sdp);
        }
        if(!r.ok){
          const msg = await r.text().catch(()=>String(r.status));
          alert('Realtime handshake failed:\n' + msg);
          throw new Error('SDP post failed ' + r.status);
        }

        const answer = { type:'answer', sdp: await r.text() };
        await pc.setRemoteDescription(answer);
        log('remote description set, waiting for connection…');

      }catch(err){
        log('startCall error:', err?.message || err);
        try{ await endCall(); }catch{}
        startBtn.disabled=false; endBtn.disabled=true;
      }
    }

    async function endCall(){
      endBtn.disabled = true;
      try{ if(silenceTimer) clearTimeout(silenceTimer); if(silenceRAF) cancelAnimationFrame(silenceRAF); }catch{}
      try{ mediaRecorder && mediaRecorder.stop(); }catch{}
      try{ pc && pc.close(); }catch{}
      try{ localStream && localStream.getTracks().forEach(t=>t.stop()); }catch{}

      try{
        if(recordedChunks.length){
          const audioBlob = new Blob(recordedChunks, { type:'audio/webm' });
          const form = new FormData();
          form.append('audio', audioBlob, 'conversation.webm');
          form.append('transcriptJson', JSON.stringify({ endedAt:new Date().toISOString() }));
          const up = await fetch('/api/upload', { method:'POST', body:form });
          log('upload status:', up.status);
        }
      }catch(e){ log('upload error:', e); }

      recordedChunks = [];
      startBtn.disabled=false;
    }

    startBtn.addEventListener('click', startCall);
    endBtn.addEventListener('click', endCall);
  </script>
</body>
</html>
