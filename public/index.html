<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>iiTuitions — Voice</title>
  <style>
    :root{ --ink:#000; --ring:#e5e7eb; --idle:#bbb; }
    *{box-sizing:border-box}
    body{
      margin:0; color:var(--ink);
      font:16px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Inter,sans-serif;
      background:linear-gradient(180deg,#9EC3F2 0%,#DCE7F7 100%); min-height:100vh;
    }
    .wrap{max-width:980px;margin:28px auto;padding:0 16px}
    .card{padding:24px;border:1px solid var(--ring);border-radius:16px;box-shadow:0 6px 28px rgba(0,0,0,.06);background:#fff}
    h1{margin:0 0 10px} p{margin:0 0 14px}
    .row{display:flex;gap:12px;align-items:center;margin-top:12px;flex-wrap:wrap}
    button{
      display:inline-flex;gap:8px;align-items:center;justify-content:center;
      padding:12px 20px;border-radius:999px;border:0;background:#000;color:#fff;font-weight:800;cursor:pointer
    }
    button:disabled{opacity:.6;cursor:not-allowed}
    .led{width:10px;height:10px;border-radius:999px;background:var(--idle)}
    audio{display:none}
    .bar{height:40px;border:1px solid #eee;border-radius:10px;display:flex;align-items:center;padding:0 12px;color:#444}
    pre{height:320px;overflow:auto;background:#fafafa;border:1px solid #eee;padding:10px;border-radius:10px}
    .dot{width:10px;height:10px;border-radius:999px;background:#bbb;display:inline-block}
    .dot.on{background:#0a0}
  </style>
</head>
<body>
  <main class="wrap">
    <section class="card">
      <h1>Talk to our Admissions Assistant</h1>
      <label style="display:flex;gap:8px;align-items:center;margin:6px 0 12px">
        <input type="checkbox" id="consent" checked>
        I agree to the recording and storage of this conversation.
      </label>

      <div class="row">
        <button id="startBtn">Start</button>
        <button id="endBtn" disabled>End</button>
        <span id="stateDot" class="dot" title="Connection state"></span>
        <audio id="aiAudio" autoplay playsinline></audio>
      </div>

      <div id="status" class="bar" style="margin-top:12px">On call. Speak normally. The assistant will reply.</div>

      <pre id="log"></pre>
    </section>
  </main>

  <script>
    const startBtn = document.getElementById('startBtn');
    const endBtn   = document.getElementById('endBtn');
    const statusEl = document.getElementById('status');
    const logEl    = document.getElementById('log');
    const aiAudio  = document.getElementById('aiAudio');
    const consent  = document.getElementById('consent');
    const dot      = document.getElementById('stateDot');

    let pc, dc, localStream;
    const println = (...a) => { console.log(...a); logEl.textContent += a.join(' ') + '\n'; logEl.scrollTop = logEl.scrollHeight; };

    function timeOfDay(){ const h=new Date().getHours(); return h<12?'morning':h<17?'afternoon':h<21?'evening':'night'; }

    async function startCall() {
      if (!consent.checked) { alert('Please provide consent to proceed.'); return; }
      startBtn.disabled = true; endBtn.disabled = false; logEl.textContent = '';

      // 1) Get ephemeral key + (optional) ICE/TURN from your backend
      let sess;
      try {
        const resp = await fetch('/api/session');
        if (!resp.ok) throw await resp.json();
        sess = await resp.json();
      } catch (e) {
        alert('Failed to create session: ' + (e?.error?.message || e?.error || JSON.stringify(e)));
        startBtn.disabled = false; endBtn.disabled = true; return;
      }
      const EPHEMERAL = sess?.client_secret?.value;
      const MODEL     = encodeURIComponent(sess?.model || 'gpt-4o-realtime-preview');
      const iceServers = sess?.iceServers || [{ urls: 'stun:stun.l.google.com:19302' }];

      // 2) Prepare audio context (autoplay constraints)
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      if (ctx.state === 'suspended') { try { await ctx.resume(); } catch {} }

      // 3) Create RTCPeerConnection up front with recv+send audio
      pc = new RTCPeerConnection({ iceServers });
      pc.addTransceiver('audio', { direction: 'sendrecv' });

      pc.oniceconnectionstatechange = () => {
        println('ice:', pc.iceConnectionState);
        dot.classList.toggle('on', pc.iceConnectionState === 'connected');
      };
      pc.onconnectionstatechange = () => println('pc:', pc.connectionState);

      // 4) Data channel for events
      dc = pc.createDataChannel('oai-events');
      dc.onmessage = (e) => {
        try {
          const msg = JSON.parse(e.data);
          if (msg.type === 'response.created') statusEl.textContent = 'Thinking…';
          if (msg.type === 'response.done')      statusEl.textContent = 'Listening…';
          if (msg.type?.includes('error') || msg.level === 'error') {
            println('OAI error:', msg); // show the object (don’t hide!!)
          } else {
            println('OAI:', msg.type || e.data);
          }
        } catch { println('OAI raw:', e.data); }
      };

      dc.onopen = () => {
        // Send a greeting as audio+text. (Use ['audio','text']—this is the valid combo.)
        const greet = `Hai. Good ${timeOfDay()}. Which language would you like—English, Telugu, or Hindi?`;
        dc.send(JSON.stringify({
          type: 'response.create',
          response: { modalities: ['audio','text'], instructions: greet }
        }));
      };

      // 5) Mic → publish
      try {
        localStream = await navigator.mediaDevices.getUserMedia({
          audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true }
        });
      } catch {
        alert('Microphone blocked. Click the mic icon in the address bar and Allow, then reload.');
        startBtn.disabled = false; endBtn.disabled = true; return;
      }
      localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

      // 6) Remote audio → play
      pc.ontrack = (ev) => {
        const [stream] = ev.streams;
        aiAudio.srcObject = stream;
        ev.track.onunmute = () => {
          println('remote track unmuted (audio flowing)');
          aiAudio.play().catch(()=>{});
        };
      };

      // 7) SDP offer/answer
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      await new Promise((resolve) => {
        if (pc.iceGatheringState === 'complete') return resolve();
        pc.onicegatheringstatechange = () => { if (pc.iceGatheringState === 'complete') resolve(); };
        setTimeout(resolve, 1500); // safety
      });

      const sdpResp = await fetch(`https://api.openai.com/v1/realtime?model=${MODEL}`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${EPHEMERAL}`,
          'Content-Type': 'application/sdp',
          'OpenAI-Beta': 'realtime=v1'
        },
        body: pc.localDescription.sdp
      });

      if (!sdpResp.ok) {
        const t = await sdpResp.text();
        println('Realtime SDP error:', t);
        alert('Realtime connection failed (model/quota/region).');
        await endCall();
        return;
      }

      const answer = { type: 'answer', sdp: await sdpResp.text() };
      await pc.setRemoteDescription(answer);

      // Tell the session to speak & auto-turn-take (also set on server, but sending once here is safe)
      dc?.send(JSON.stringify({
        type: 'session.update',
        session: {
          modalities: ['audio','text'],
          voice: 'verse',
          turn_detection: { type: 'server_vad', silence_duration_ms: 700 }
        }
      }));

      statusEl.textContent = 'Listening…';
    }

    async function endCall() {
      endBtn.disabled = true;
      statusEl.textContent = 'Ending…';

      try { pc && pc.close(); } catch {}
      try { localStream && localStream.getTracks().forEach(t => t.stop()); } catch {}
      pc = null; dc = null; localStream = null;
      dot.classList.remove('on');

      statusEl.textContent = 'Call ended.';
      startBtn.disabled = false;
    }

    startBtn.addEventListener('click', startCall);
    endBtn.addEventListener('click', endCall);
    window.addEventListener('beforeunload', () => { try { pc && pc.close(); } catch {} });
  </script>
</body>
</html>
