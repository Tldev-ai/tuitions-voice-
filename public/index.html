<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>iiTuitions — Voice (Realtime)</title>
  <style>
    :root{--ink:#000;--ring:#e5e7eb;--idle:#bbb}
    *{box-sizing:border-box}
    body{margin:0;color:var(--ink);font:16px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Inter,sans-serif;background:linear-gradient(180deg,#9EC3F2 0%,#DCE7F7 100%);min-height:100vh}
    .wrap{max-width:940px;margin:28px auto;padding:0 16px}
    .card{padding:24px;border:1px solid var(--ring);border-radius:16px;box-shadow:0 6px 28px rgba(0,0,0,.06);background:#fff}
    h1{margin:0 0 10px}
    label{display:flex;align-items:center;gap:8px;margin:8px 0 16px}
    .row{display:flex;gap:12px;align-items:center;margin-top:8px;flex-wrap:wrap}
    button{display:inline-flex;gap:8px;align-items:center;justify-content:center;padding:14px 24px;border-radius:999px;border:0;background:#000;color:#fff;font-weight:800;cursor:pointer}
    button:disabled{opacity:.6;cursor:not-allowed}
    #startBtn{min-width:200px}
    #endBtn{background:#222}
    .led{width:10px;height:10px;border-radius:999px;background:var(--idle);box-shadow:0 0 0 1px #0001}
    .led.on{background:#000}
    #status{font:13px;margin-top:8px;opacity:.85}
    #log{font:12px/1.4 ui-monospace,Menlo,monospace;background:#fafafa;border:1px solid #eee;padding:10px;border-radius:10px;max-height:240px;overflow:auto;margin-top:12px;white-space:pre-wrap}
  </style>
</head>
<body>
  <main class="wrap">
    <section class="card">
      <h1>Talk to our Admissions Assistant</h1>
      <label><input type="checkbox" id="consent"/> I agree to the recording and storage of this conversation.</label>
      <div class="row">
        <button id="startBtn">Start</button>
        <button id="endBtn" disabled>End</button>
        <span class="led" id="led" title="Mic activity"></span>
        <audio id="aiAudio" autoplay playsinline></audio>
      </div>
      <div id="status">Idle.</div>
      <div id="log"></div>
    </section>
  </main>

  <script>
    const startBtn = document.getElementById('startBtn');
    const endBtn   = document.getElementById('endBtn');
    const consent  = document.getElementById('consent');
    const aiAudio  = document.getElementById('aiAudio');
    const led      = document.getElementById('led');
    const statusEl = document.getElementById('status');
    const logEl    = document.getElementById('log');

    let pc, dc, localStream, remoteStream, analyser, dataArray, raf;

    const log = (...a)=>{ logEl.textContent += a.map(x=>typeof x==='string'?x:JSON.stringify(x)).join(' ')+'\n'; logEl.scrollTop = logEl.scrollHeight; };
    const setStatus = (s)=>{ statusEl.textContent = s; };

    function timeOfDay(){ const h=new Date().getHours(); return h<12?'morning':h<17?'afternoon':h<21?'evening':'night'; }

    startBtn.onclick = startCall;
    endBtn.onclick = endCall;
    window.addEventListener('beforeunload', endCall);

    async function startCall(){
      if (!consent.checked){ alert('Please provide consent to proceed.'); return; }
      startBtn.disabled = true; endBtn.disabled = false;
      setStatus('Connecting…');

      // 1) Get ephemeral session + ICE
      let sess;
      try{
        const r = await fetch('/api/session');
        if(!r.ok) throw new Error((await r.text())||'session failed');
        sess = await r.json();
      }catch(e){
        alert('Failed to create session:\n' + (e?.message || e));
        startBtn.disabled = false; endBtn.disabled = true;
        return;
      }
      const EPHEMERAL = sess?.client_secret?.value;
      const MODEL     = encodeURIComponent(sess?.model || 'gpt-4o-realtime-preview');
      const iceServers= sess?.iceServers || [{ urls:['stun:stun.l.google.com:19302'] }];

      // 2) Create RTCPeerConnection
      pc = new RTCPeerConnection({ iceServers });
      pc.addTransceiver('audio', { direction: 'sendrecv' });

      pc.oniceconnectionstatechange = () => {
        log('ice:', pc.iceConnectionState);
        if (pc.iceConnectionState === 'failed' || pc.iceConnectionState === 'disconnected') setStatus('Network issue. You can End and try again.');
      };
      pc.onconnectionstatechange = () => {
        log('pc:', pc.connectionState);
        if (pc.connectionState === 'connected') setStatus('On call. Speak normally. The assistant will reply.');
        if (pc.connectionState === 'failed') setStatus('Call failed. End and retry.');
      };

      // 3) Data channel for events
      dc = pc.createDataChannel('oai-events');
      dc.onmessage = (e)=>{
        try{
          const msg = JSON.parse(e.data);
          if (msg?.type?.includes?.('error') || msg?.level === 'error') { console.error('OAI error:', msg); }
          else log('OAI:', msg?.type || e.data);
        }catch{ log('OAI raw:', e.data); }
      };

      dc.onopen = () => {
        // Configure session to speak & detect turns automatically
        dc.send(JSON.stringify({
          type: 'session.update',
          session: {
            modalities: ['audio','text'],
            voice: 'verse',
            turn_detection: { type: 'server_vad', silence_duration_ms: 500 }
          }
        }));
        // Friendly greeting (omit modalities here; session modalites already include audio)
        dc.send(JSON.stringify({
          type: 'response.create',
          response: { instructions: `Hai. Good ${timeOfDay()}! Which language would you like — English, తెలుగు, or हिन्दी? To begin, may I know the student's grade and target exam window?` }
        }));
      };

      // 4) Publish microphone
      try{
        localStream = await navigator.mediaDevices.getUserMedia({
          audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true }
        });
      }catch{
        alert('Microphone blocked. Click the mic icon in the address bar → Allow, then reload.');
        startBtn.disabled = false; endBtn.disabled = true; return;
      }
      localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

      // LED feedback
      try{
        const ctx = new (window.AudioContext || window.webkitAudioContext)();
        const src = ctx.createMediaStreamSource(localStream);
        analyser = ctx.createAnalyser(); analyser.fftSize = 2048; dataArray = new Float32Array(analyser.fftSize);
        src.connect(analyser);
        const loop = ()=>{ analyser.getFloatTimeDomainData(dataArray); let s=0; for(let i=0;i<dataArray.length;i++){ s+=dataArray[i]*dataArray[i]; } const rms=Math.sqrt(s/dataArray.length); if (rms>0.006) led.classList.add('on'); else led.classList.remove('on'); raf=requestAnimationFrame(loop); };
        raf=requestAnimationFrame(loop);
      }catch{}

      // 5) Play remote audio
      pc.ontrack = (ev) => {
        if (!remoteStream) remoteStream = ev.streams[0];
        aiAudio.srcObject = remoteStream;
        aiAudio.muted = false;
        aiAudio.play().catch(()=>{});
        log('remote track unmuted (audio flowing)');
      };

      // 6) SDP offer/answer
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      await new Promise((resolve)=>{
        if (pc.iceGatheringState === 'complete') return resolve();
        pc.onicegatheringstatechange = () => { if (pc.iceGatheringState === 'complete') resolve(); };
        setTimeout(resolve, 1500); // safety
      });

      const sdpResp = await fetch(`https://api.openai.com/v1/realtime?model=${MODEL}`, {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${EPHEMERAL}`,
          'Content-Type': 'application/sdp',
          'OpenAI-Beta': 'realtime=v1'
        },
        body: pc.localDescription.sdp
      });

      if (!sdpResp.ok) {
        const t = await sdpResp.text().catch(()=>String(sdpResp.status));
        alert('Realtime connection failed:\n' + t);
        endCall();
        return;
      }

      const answer = { type: 'answer', sdp: await sdpResp.text() };
      if (pc.signalingState === 'stable') {
        // already connected somehow; ignore
      } else {
        await pc.setRemoteDescription(answer);
      }

      setStatus('On call. Speak normally.');
    }

    async function endCall(){
      try { if (raf) cancelAnimationFrame(raf); } catch {}
      try { localStream && localStream.getTracks().forEach(t=>t.stop()); } catch {}
      try { pc && pc.close(); } catch {}
      pc = null; dc = null; localStream = null; remoteStream = null;
      startBtn.disabled = false; endBtn.disabled = true;
      led.classList.remove('on');
      setStatus('Call ended.');
    }
  </script>
</body>
</html>
