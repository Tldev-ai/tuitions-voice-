<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta http-equiv="Cache-Control" content="no-store" />
  <title>iiTuitions ‚Äî Voice (Push-to-Talk)</title>
  <style>
    :root{ --ink:#000; --ring:#e5e7eb; --idle:#bbb; }
    *{box-sizing:border-box}
    body{ margin:0; color:var(--ink); font:16px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Inter,sans-serif;
      background:linear-gradient(180deg,#9EC3F2 0%,#DCE7F7 100%); min-height:100vh; }
    .wrap{max-width:920px;margin:28px auto;padding:0 16px}
    .card{padding:24px;border:1px solid var(--ring);border-radius:16px;box-shadow:0 6px 28px rgba(0,0,0,.06);background:#fff}
    h1{margin:0 0 10px}
    .row{display:flex;gap:12px;align-items:center;margin-top:12px;flex-wrap:wrap}
    button{display:inline-flex;gap:8px;align-items:center;justify-content:center;padding:14px 22px;border-radius:999px;border:0;background:#000;color:#fff;font-weight:800;cursor:pointer}
    #talkBtn{min-width:200px}
    #endBtn{background:#222}
    .led{width:10px;height:10px;border-radius:999px;background:var(--idle);box-shadow:0 0 0 1px #0001}
    .led.on{background:#000}
    #log{font:12px/1.4 ui-monospace, SFMono-Regular, Menlo, monospace; white-space:pre-wrap; background:#fafafa; border:1px solid #eee; padding:10px; border-radius:10px; max-height:240px; overflow:auto; margin-top:12px}
  </style>
</head>
<body>
  <main class="wrap">
    <section class="card">
      <h1>Talk to our Admissions Assistant</h1>

      <label style="display:flex;align-items:center;gap:8px;margin-top:10px">
        <input type="checkbox" id="consent" />
        I agree to the recording and storage of this conversation.
      </label>

      <div class="row">
        <button id="talkBtn">üé§ Start</button>
        <button id="endBtn">‚èπÔ∏è End</button>
        <span class="led" id="led" title="Mic activity"></span>
        <audio id="aiAudio" autoplay playsinline></audio>
      </div>

      <div id="log"></div>
    </section>
  </main>

  <script>
    const talkBtn = document.getElementById('talkBtn');
    const endBtn  = document.getElementById('endBtn');
    const aiAudio = document.getElementById('aiAudio');
    const led     = document.getElementById('led');
    const consent = document.getElementById('consent');
    const logEl   = document.getElementById('log');

    let rec, chunks = [], recording = false, ctx, analyser, dataArray, raf, mediaStream;
    const RMS_THRESHOLD = 0.006, SILENCE_HANG_MS = 1200, MAX_MS = 12000;
    const history = [];
    let inFlight = false, greeted = false;

    function log(...a){ const s=a.map(x=>typeof x==='string'?x:JSON.stringify(x,null,2)).join(' '); logEl.textContent += s+'\n'; logEl.scrollTop = logEl.scrollHeight; }

    function cancelSynth() {
      try { speechSynthesis.cancel(); } catch {}
    }
    function stopAudio() {
      try { aiAudio.pause(); aiAudio.currentTime = 0; aiAudio.removeAttribute('src'); aiAudio.load(); } catch {}
    }
    function resetUI() {
      talkBtn.disabled = false;
      talkBtn.textContent = 'üé§ Start';
      led.classList.remove('on');
    }

    talkBtn.addEventListener('click', () => {
      if (!consent.checked) { alert('Please provide consent to proceed.'); return; }
      if (!greeted) { playGreetingThenListen(); return; }
      if (recording) stopRecording(); else startRecording();
    });
    endBtn.addEventListener('click', endSession);
    window.addEventListener('beforeunload', endSession);

    // ---- GREETING ----
    async function playGreetingThenListen(){
      if (inFlight) return; inFlight = true;
      cancelSynth(); stopAudio();
      talkBtn.disabled = true; talkBtn.textContent = 'ü§ñ Greeting‚Ä¶';
      try {
        const r = await fetch('/api/answer', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ greet: true })
        });
        const j = await r.json().catch(()=>({}));
        if (!r.ok) throw new Error(j?.error?.message || `HTTP ${r.status}`);
        if (j.reply) log('AI:', j.reply);

        if (j.audio) {
          aiAudio.src = j.audio;
          aiAudio.onended = () => { startRecording(); };
          await aiAudio.play().catch(()=>{});
          greeted = true;
        } else {
          throw new Error('No audio from server');
        }
      } catch (e) {
        console.warn('Greeting TTS failed:', e?.message || e);
        alert('Failed to play greeting. You can still talk; I will reply.');
        const fallbackText =
`Hai! This is iiTuitions admissions assistant.
Which language would you like ‚Äî English, Telugu, or Hindi?
To begin, please tell me the student‚Äôs grade and target exam window.`;
        try {
          const utter = new SpeechSynthesisUtterance(fallbackText);
          utter.rate = 1; utter.pitch = 1; utter.lang = 'en-IN';
          speechSynthesis.speak(utter);
        } catch {}
        greeted = true;
        startRecording();
      } finally {
        inFlight = false; talkBtn.disabled = false; talkBtn.textContent = 'üéôÔ∏è Start';
      }
    }

    // ---- RECORDING ----
    async function startRecording(){
      if (recording || inFlight) return;
      cancelSynth(); stopAudio();

      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true }
        });
      } catch { alert('Microphone blocked. Click Allow and reload.'); return; }

      ctx = new (window.AudioContext || window.webkitAudioContext)();
      if (ctx.state === 'suspended') await ctx.resume();
      const src = ctx.createMediaStreamSource(mediaStream);
      analyser = ctx.createAnalyser(); analyser.fftSize = 2048;
      dataArray = new Float32Array(analyser.fftSize);
      src.connect(analyser);

      try { rec = new MediaRecorder(mediaStream, { mimeType:'audio/webm;codecs=opus' }); }
      catch { rec = new MediaRecorder(mediaStream); }
      chunks = [];
      rec.ondataavailable = e => { if (e.data.size>0) chunks.push(e.data); };
      rec.onstop = onStop;

      rec.start(250);
      recording = true;
      talkBtn.textContent = '‚èπÔ∏è Stop (auto on silence)';
      led.classList.add('on');
      log('Listening‚Ä¶');

      const startAt = Date.now(); let lastLoud = Date.now();
      const loop = () => {
        if (!recording) return;
        analyser.getFloatTimeDomainData(dataArray);
        let rms=0; for (let i=0;i<dataArray.length;i++){ const v=dataArray[i]; rms += v*v; }
        rms = Math.sqrt(rms / dataArray.length);
        if (rms > RMS_THRESHOLD) lastLoud = Date.now();

        const t = Date.now();
        if (t - lastLoud > 1200 || t - startAt > 12000) { stopRecording(); return; }
        raf = requestAnimationFrame(loop);
      };
      raf = requestAnimationFrame(loop);
    }

    function stopRecording(){
      if (!recording) return;
      recording = false;
      try { rec.stop(); } catch {}
      try { mediaStream.getTracks().forEach(t=>t.stop()); } catch {}
      try { if (raf) cancelAnimationFrame(raf); } catch {}
      try { ctx && ctx.close(); } catch {}
      led.classList.remove('on');
      talkBtn.textContent = 'üé§ Start';
    }

    async function onStop(){
      const blob = new Blob(chunks, { type:'audio/webm' });
      const b64 = await blobToDataURL(blob);
      await sendToServer(b64);
    }

    function blobToDataURL(blob){
      return new Promise((res, rej) => {
        const reader = new FileReader();
        reader.onloadend = () => res(reader.result);
        reader.onerror = rej;
        reader.readAsDataURL(blob);
      });
    }

    // ---- SEND TO SERVER ----
    async function sendToServer(dataUrl){
      if (inFlight) return; inFlight = true;
      talkBtn.disabled = true; talkBtn.textContent = '‚è≥ Thinking‚Ä¶';

      let attempts = 0, ok = false, lastError = null;
      while (attempts < 3 && !ok) {
        attempts++;
        const resp = await fetch('/api/answer', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ audio: dataUrl, history }),
        });
        if (resp.ok) {
          const j = await resp.json();
          if (j.userText) { history.push({ role:'user', content:j.userText }); log('You:', j.userText); }
          if (j.reply)    { history.push({ role:'assistant', content:j.reply }); log('AI:', j.reply); }
          if (j.audio) { cancelSynth(); aiAudio.src = j.audio; aiAudio.play().catch(()=>{}); }
          ok = true;
        } else {
          let details = {};
          try { details = await resp.json(); } catch {}
          lastError = details?.error?.message || `HTTP ${resp.status}`;
          if (resp.status === 429 || resp.status >= 500) {
            const backoff = 400 * Math.pow(2, attempts-1) + Math.random()*120;
            await new Promise(r => setTimeout(r, backoff));
          } else break;
        }
      }

      if (!ok) {
        console.error('Answer error:', { message:lastError });
        alert('Failed to get answer: ' + (lastError || 'unknown error'));
      }

      inFlight = false; talkBtn.disabled = false; talkBtn.textContent = 'üé§ Start';
    }

    // ---- END/RESET ----
    function endSession() {
      cancelSynth(); stopAudio();
      if (recording) stopRecording();
      try { mediaStream && mediaStream.getTracks().forEach(t=>t.stop()); } catch {}
      try { ctx && ctx.close(); } catch {}
      history.length = 0;
      greeted = false;
      resetUI();
      log('‚Äî session ended ‚Äî');
    }
  </script>
</body>
</html>
