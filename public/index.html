<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <meta http-equiv="Cache-Control" content="no-store" />
  <title>iiTuitions ‚Äî Voice (HTTP)</title>
  <style>
    :root{ --ink:#000; --ring:#e5e7eb; --idle:#bbb; }
    *{box-sizing:border-box}
    body{ margin:0; color:var(--ink); font:16px/1.45 system-ui,-apple-system,Segoe UI,Roboto,Inter,sans-serif;
      background:linear-gradient(180deg,#9EC3F2 0%,#DCE7F7 100%); min-height:100vh; }
    .wrap{max-width:920px;margin:28px auto;padding:0 16px}
    .card{padding:24px;border:1px solid var(--ring);border-radius:16px;box-shadow:0 6px 28px rgba(0,0,0,.06);background:#fff}
    h1{margin:0 0 10px}
    .row{display:flex;gap:12px;align-items:center;margin-top:12px;flex-wrap:wrap}
    button{display:inline-flex;gap:8px;align-items:center;justify-content:center;padding:12px 16px;border-radius:999px;border:0;background:#000;color:#fff;font-weight:800;cursor:pointer}
    #talkBtn{min-width:260px}
    .led{width:10px;height:10px;border-radius:999px;background:var(--idle);box-shadow:0 0 0 1px #0001}
    .led.on{background:#000}
    #log{font:12px/1.4 ui-monospace, SFMono-Regular, Menlo, monospace; white-space:pre-wrap; background:#fafafa; border:1px solid #eee; padding:10px; border-radius:10px; max-height:200px; overflow:auto}
  </style>
</head>
<body>
  <main class="wrap">
    <section class="card">
      <h1>Talk to our Admissions Assistant</h1>

      <label style="display:flex;align-items:center;gap:8px;margin-top:10px">
        <input type="checkbox" id="consent" />
        I agree to the recording and storage of this conversation.
      </label>

      <div class="row">
        <button id="talkBtn">üéôÔ∏è Start talking</button>
        <span class="led" id="led" title="Mic activity"></span>
        <audio id="aiAudio" autoplay playsinline></audio>
      </div>

      <div id="log"></div>
    </section>
  </main>

  <script>
    const talkBtn = document.getElementById('talkBtn');
    const aiAudio = document.getElementById('aiAudio');
    const led     = document.getElementById('led');
    const consent = document.getElementById('consent');
    const logEl   = document.getElementById('log');

    let rec, chunks = [], recording = false, ctx, analyser, dataArray, raf, mediaStream;
    const RMS_THRESHOLD = 0.006, SILENCE_HANG_MS = 1200, MAX_MS = 12000;

    const history = []; // [{role:'user'|'assistant', content:'...'}]

    function log(...a){ const s=a.map(x=>typeof x==='string'?x:JSON.stringify(x,null,2)).join(' '); logEl.textContent += s+'\n'; logEl.scrollTop = logEl.scrollHeight; }

    async function startRecording(){
      if (!consent.checked) { alert('Please provide consent to proceed.'); return; }
      if (recording) return;

      try {
        mediaStream = await navigator.mediaDevices.getUserMedia({
          audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true }
        });
      } catch {
        alert('Microphone blocked. Click Allow and reload.'); return;
      }

      // WebAudio for VAD
      ctx = new (window.AudioContext || window.webkitAudioContext)();
      if (ctx.state === 'suspended') await ctx.resume();
      const src = ctx.createMediaStreamSource(mediaStream);
      analyser = ctx.createAnalyser(); analyser.fftSize = 2048;
      dataArray = new Float32Array(analyser.fftSize);
      src.connect(analyser);

      // MediaRecorder for audio
      try {
        rec = new MediaRecorder(mediaStream, { mimeType:'audio/webm;codecs=opus' });
      } catch {
        rec = new MediaRecorder(mediaStream);
      }
      chunks = [];
      rec.ondataavailable = e => { if (e.data.size>0) chunks.push(e.data); };
      rec.onstop = onStop;

      rec.start(250);
      recording = true;
      talkBtn.textContent = '‚èπÔ∏è Stop (auto when silent)';
      led.classList.add('on');
      log('Listening‚Ä¶');

      // auto-stop on silence or max duration
      const startAt = Date.now();
      let lastLoud = Date.now();

      const loop = () => {
        if (!recording) return;
        analyser.getFloatTimeDomainData(dataArray);
        let rms=0; for (let i=0;i<dataArray.length;i++){ const v=dataArray[i]; rms += v*v; }
        rms = Math.sqrt(rms / dataArray.length);
        if (rms > RMS_THRESHOLD) lastLoud = Date.now();

        const t = Date.now();
        if (t - lastLoud > SILENCE_HANG_MS || t - startAt > MAX_MS) {
          stopRecording(); return;
        }
        raf = requestAnimationFrame(loop);
      };
      raf = requestAnimationFrame(loop);
    }

    function stopRecording(){
      if (!recording) return;
      recording = false;
      try { rec.stop(); } catch {}
      try { mediaStream.getTracks().forEach(t=>t.stop()); } catch {}
      try { if (raf) cancelAnimationFrame(raf); } catch {}
      try { ctx && ctx.close(); } catch {}
      led.classList.remove('on');
      talkBtn.textContent = 'üéôÔ∏è Start talking';
    }

    async function onStop(){
      const blob = new Blob(chunks, { type:'audio/webm' });
      const b64 = await blobToDataURL(blob); // data:audio/webm;base64,....
      await sendToServer(b64);
    }

    function blobToDataURL(blob){
      return new Promise((res, rej) => {
        const reader = new FileReader();
        reader.onloadend = () => res(reader.result);
        reader.onerror = rej;
        reader.readAsDataURL(blob);
      });
    }

    async function sendToServer(dataUrl){
      log('Sending audio‚Ä¶');
      const resp = await fetch('/api/answer', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ audio: dataUrl, history }),
      });
      const j = await resp.json().catch(()=>({}));
      if (!resp.ok) {
        console.error('Answer error:', j);
        alert('Failed to get answer'); return;
      }

      const { userText, reply, audio } = j;
      if (userText) { history.push({ role:'user', content:userText }); log('You:', userText); }
      if (reply)    { history.push({ role:'assistant', content:reply }); log('AI:', reply); }

      if (audio) {
        aiAudio.src = audio;
        aiAudio.play().catch(err => console.warn('play failed:', err));
      }
    }

    talkBtn.addEventListener('click', () => {
      if (recording) stopRecording();
      else startRecording();
    });
  </script>
</body>
</html>
